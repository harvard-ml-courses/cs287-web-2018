tas:
  - name: <a href="mailto:yoonkim@g.harvard.edu">Yoon</a>
  - name: <a href="mailto:carldenton@college.harvard.edu">Carl</a>


dates: ["", "Jan. 23", "Jan. 25", "Jan. 30", "Feb. 1", "Feb. 6", "Feb. 8", "Feb. 13", "Feb. 15","Feb. 20", "Feb. 22", "Feb. 27.", "Mar. 1", "Mar. 6.", "Mar. 8", "Mar. 20", "Mar. 22", "Mar. 27", "Mar. 29", "Apr. 3", "Apr. 5", "Apr. 10", "Apr. 12", "Apr. 17", "Apr. 19", "Apr. 24"]
ohs:
  - time: Tuesday 2:30-4pm
    location: MD 217 (Sasha)
  - time: Wednesday 7-9pm
    location: MD 2nd Floor (Yoon)



lectures:
  - topic: Sequence Classification
    subtopic: Bag-of-Words
    hw:
    papers:
      - name: "Torch: PyTorch Deep Learning Tutorial"
        link: "http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
      - name: "Fundamental: Baselines and Bigrams"
        cite: "wang2012baselines"
      - name: "Word Representations in Vector Space"
        cite: "mikolovchen"
    section:
    demos:
  - topic:
    subtopic: Convolutions
    hw: <a href="https://github.com/harvard-ml-courses/cs287-s18/blob/master/HW1/Homework%201.ipynb">Classification</a> (Mon @ midnight) <a href="https://www.kaggle.com/c/harvard-cs281-hw1">(Kaggle)</a>
    papers:
      - name: "PyTorch NLP Tutorial"
        link: "http://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html"
      - name: "Natural language processing (almost) from scratch"
        cite: "collobert2011natural"
      - name: "CNNs for Sentence Classification"
        cite: "DBLP:conf/emnlp/Kim14"
    section:
    demos:
  - topic: Sequence Modeling
    hw:
    subtopic: NNLMs
    papers:
      - name: "A Neural Probabilistic Language Model"
        link: "http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
      - name: "Three New Graphical Models for Statistical Language Modelling"
        link: "https://www.cs.toronto.edu/~amnih/papers/threenew.pdf"
  - topic:
    subtopic: RNNs
    hw:
    papers:
      - name: "Recurrent Neural Network-Based Language Model"
        link: "http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf"
      - name: "Understanding LSTM Networks"
        link: "http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      - name: "Generating Text with Recurrent Neural Networks"
        link: "http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf"
      - name: "The Unreasonable Effectiveness of Recurrent Neural Networks"
        link: "http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
    section:
    demos:
  - topic: Sequence Transduction
    subtopic: Encoding
    papers:
      - name: "Sequence-to-Sequence Learning with Recurrent Neural Networks"
        link: "https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf"
      - name: "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation"
        link: "https://arxiv.org/pdf/1406.1078.pdf"
  - topic:
    subtopic: Attention
    hw: <a href="https://github.com/harvard-ml-courses/cs287-s18/HW2/">Modeling</a> <a href="https://www.kaggle.com/c/cs287-hw2-s18">(Kaggle)</a>
    papers:
      - name: "Neural Machine Translation by Jointly Learning to Align and Translate"
        link: "https://arxiv.org/abs/1409.0473"
      - name: "Effective Approaches to Attention-based Neural Machine Translation"
        link: "https://arxiv.org/pdf/1508.04025.pdf"
      - name: "Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention"
        link: "https://arxiv.org/pdf/1502.03044.pdf"
    section:
    demos:
  - topic:
    subtopic: Search
    hw:
    papers:
      - name: "Sequence-to-Sequence Learning as Beam-Search Optimization"
        link: "https://arxiv.org/pdf/1606.02960.pdf"
      - name: "Sequence-level Training with Recurrent Neural Networks"
        link: "https://arxiv.org/pdf/1511.06732.pdf"
  - topic: Variational Inference
    hw:
    subtopic: Basics
    papers:
      - name: "Variational Inference: A Review for Statisticians"
        link: "https://arxiv.org/abs/1601.00670"
      - name: "Graphical Models, Exponential Familes, and Variational Inference"
        link: "https://people.eecs.berkeley.edu/~wainwrig/Papers/WaiJor08_FTML.pdf"
  - topic:
    subtopic: VAEs
    hw:
    papers:
      - name: "Auto-Encoding Variable Bayes"
        link: "https://arxiv.org/abs/1312.6114"
      - name: "Semi-Supervised Learning with Deep Generative Models"
        link: "https://arxiv.org/abs/1406.5298"
    section:
    demos:
  - topic: Other Latent Variable Techniques
    subtopic: GANs
    papers:
      - name: "Generative Adversarial Networks"
        link: "https://arxiv.org/abs/1406.2661"
      - name: "NIPS 2016 GAN Tutorial"
        link: "https://arxiv.org/pdf/1701.00160.pdf"
    hw: <a href="https://github.com/harvard-ml-courses/cs287-s18/HW3/">Attention</a> <a href="https://www.kaggle.com/c/cs287-hw3-s18">(Kaggle)</a>
  - topic:
    subtopic: REINFORCE
    papers:
      - name: "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcment Learning"
        link: "http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf"
      - name: "Gradient Estimation Using Stochastic Computation Graphs"
        link: "https://arxiv.org/abs/1506.05254"
  - topic: Guest Lecture (Structured Training for NMT)
    subtopic:
    hw:
  - topic: Midterm
    subtopic:
    hw:

  - topic: Latent Variable Models
    subtopic: Sequence VAEs
    hw: <a href="https://github.com/harvard-ml-courses/cs287-s18/HW4/">VI</a> <a href="https://www.kaggle.com/c/cs287-hw4-s18">(Kaggle)</a>
    papers:
      - name: "Generating Sentences from a Continuous Space"
        link: "https://arxiv.org/pdf/1511.06349.pdf"
      - name: "A Recurrent Latent Variable Model for Sequential Data"
        link: "http://papers.nips.cc/paper/5653-a-recurrent-latent-variable-model-for-sequential-data.pdf"
      - name: "Improved Variational Autoencoders for Text Modeling using Dilated Convolutions"
        link: "https://arxiv.org/pdf/1702.08139.pdf"
  - topic:
    subtopic: Sampling Improvements
    hw:
  - topic:
    subtopic: Structured VAEs
    papers:
      - name: "Structured Inference Networks for Nonlinear State Space Models"
        link: "https://arxiv.org/pdf/1609.09869.pdf"
      - name: "Composing graphical models with neural networks for structured representations and fast inference"
        link: "https://arxiv.org/pdf/1603.06277.pdf"
    hw: Final Project Topics
  - topic: Discrete Variables
    subtopic: REINFORCE for text
  - topic:
    subtopic: Discrete VAEs
    hw: Project Abstract Due
  - topic: Dynamic Networks
    subtopic: Training with Search
  - topic:
    subtopic: Neural Module Networks
  - topic: NMT
    subtopic: Recent advances in NMT
  - topic:
    subtopic: Unsupervised NMT
    hw:
  - topic: Topics
    subtopic: Latent Variable Models in Science
  - topic:
    subtopic:  Latent Variable Models in Vision
  - topic: Interpretation
    subtopic:  Rationale Generation
